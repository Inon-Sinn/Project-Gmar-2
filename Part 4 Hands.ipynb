{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center><h1> Hands Movement<h1><center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### What is the hands Movement dataset\n",
    "\n",
    "This is a data set of an experiment were 12 peoples hand movments were recorde for a period of time, the recorded hand movments were of a person alone, 2 people moving their hands in sync and 2 people moving their hand however they want.\n",
    "\n",
    "#### What is the goal if this Model?\n",
    "\n",
    "the goal is  to try make a model which can if given frame of time know if the movement was done alone, in sync or spontanious"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature description\n",
    "\n",
    "**Time:** The time at which the frame was taken\n",
    "\n",
    "**Frame ID:** ID of the Frame\n",
    "\n",
    "**Hand Type** Left or Right hand\n",
    "\n",
    "**hands** how many hands were recorded during this frame\n",
    "\n",
    "**Position X** hand postion on the x axis\n",
    "\n",
    "**Position Y** hand postion on the y axis\n",
    "\n",
    "**Position Z** hand postion on the z axis (height)\n",
    "\n",
    "**Velocity X** hand movement Velocity on the X axis\n",
    "\n",
    "**Velocity Y** hand movement Velocity on the Y axis\n",
    "\n",
    "**Velocity Z** hand movement Velocity on the Z axis\n",
    "\n",
    "**Pitch** hand position (the position of the hand up or down compared to your wrist an example: stop sign would be 1 and puting the hand horizontal would be 0)\n",
    "\n",
    "**Roll** hand position (how much is the hand rolled, holdin your hand horizontal would be 0)\n",
    "\n",
    "**Yaw** hand position (the position of the hand to the rigth or left compared to your wrist)\n",
    "\n",
    "**Wrist Pos X** wrist postion on the x axis\n",
    "\n",
    "**Wrist Pos Y** wrist postion on the y axis\n",
    "\n",
    "**Wrist Pos Z** wrist postion on the z axis\n",
    "\n",
    "**Elbow pos X** wrist postion on the x axis\n",
    "\n",
    "**Elbow pos Y** wrist postion on the y axis\n",
    "\n",
    "**Elbow pos Z** wrist postion on the z axis\n",
    "\n",
    "**Grab Strenth** only has 0,1: 0 for an open hand and 1 for a closed one\n",
    "\n",
    "**Grab Angle** how closed the hand is: 0 for an open hend and 1 for closed one\n",
    "\n",
    "**Pinch Strength** ???"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "%matplotlib inline\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import cv2\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Getting insight of the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create a Test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make copy to avoid changing original data\n",
    "dfCopy = df.copy()\n",
    "\n",
    "#first lets split the data for training and testing\n",
    "X= dfCopy.drop([\"Target_feature\"],axis =1)\n",
    "y= dfCopy[\"Target_feature\"]\\\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y,test_size=0.3, random_state=7)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Preproccesing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We want to use Pca so we need to normalize the data first, Lets creat a pipeline which does it in one go"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preprocessing Pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We want use pca so we first have to normalize the data with a scaler."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 276,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "pre_process = Pipeline([\n",
    "    ('scaler',StandardScaler()),\n",
    "    ('pca',PCA(n_components=0.95))])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Transforming the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# we will preprocess the data\n",
    "X_train_transformed = pre_process.fit_transform(X_train)\n",
    "X_test_transformed = pre_process.transform(X_test)\n",
    "X_train_transformed"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.ensemble import BaggingClassifier\n",
    "from sklearn.ensemble import StackingClassifier\n",
    "\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#fit the model\n",
    "Knn = KNeighborsClassifier(n_neighbors=5,n_jobs=-1)\n",
    "Knn.fit(X_train_transformed,y_train)\n",
    "\n",
    "#make predictions\n",
    "PredicKnn = Knn.predict(X_test_transformed)\n",
    "\n",
    "#evaluate predictions\n",
    "confmat = confusion_matrix(y_test, PredicKnn)\n",
    "sns.heatmap(confmat, annot = True, fmt = \"d\")\n",
    "class_rep = classification_report(y_test, PredicKnn)\n",
    "Knn_score = accuracy_score(y_test, PredicKnn)\n",
    "print(class_rep)\n",
    "print(\"Accuracy: \", Knn_score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#fit the model\n",
    "logR = LogisticRegression(random_state=42, n_jobs=-1)\n",
    "logR.fit(X_train_transformed,y_train)\n",
    "\n",
    "#make predictions\n",
    "PredicLogR = logR.predict(X_test_transformed)\n",
    "\n",
    "#evaluate predictions\n",
    "confmat = confusion_matrix(y_test, PredicLogR)\n",
    "sns.heatmap(confmat, annot = True, fmt = \"d\")\n",
    "class_rep = classification_report(y_test, PredicLogR)\n",
    "logR_score = accuracy_score(y_test, PredicLogR)\n",
    "print(class_rep)\n",
    "print(\"Accuracy: \", logR_score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Desicion Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#fit the model\n",
    "dTree = DecisionTreeClassifier(random_state=42)\n",
    "dTree.fit(X_train_transformed,y_train)\n",
    "\n",
    "#make predictions\n",
    "PredicDeTree = dTree.predict(X_test_transformed)\n",
    "\n",
    "#evaluate predictions\n",
    "confmat = confusion_matrix(y_test, PredicDeTree)\n",
    "sns.heatmap(confmat, annot = True, fmt = \"d\")\n",
    "class_rep = classification_report(y_test, PredicDeTree)\n",
    "dTree_score = accuracy_score(y_test, PredicDeTree)\n",
    "print(class_rep)\n",
    "print(\"Accuracy: \", dTree_score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#fit the model\n",
    "RFor = RandomForestClassifier(random_state=42)\n",
    "RFor.fit(X_train_transformed,y_train)\n",
    "\n",
    "#make predictions\n",
    "PredicRFor = RFor.predict(X_test_transformed)\n",
    "\n",
    "#evaluate predictions\n",
    "confmat = confusion_matrix(y_test, PredicRFor)\n",
    "sns.heatmap(confmat, annot = True, fmt = \"d\")\n",
    "class_rep = classification_report(y_test, PredicRFor)\n",
    "RFor_score = accuracy_score(y_test, PredicRFor)\n",
    "print(class_rep)\n",
    "print(\"Accuracy: \", RFor_score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gradient Boost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#fit the model\n",
    "gradB = GradientBoostingClassifier(random_state=42)\n",
    "gradB.fit(X_train_transformed,y_train)\n",
    "\n",
    "#make predictions\n",
    "PredicGradB = gradB.predict(X_test_transformed)\n",
    "\n",
    "#evaluate predictions\n",
    "confmat = confusion_matrix(y_test, PredicGradB)\n",
    "sns.heatmap(confmat, annot = True, fmt = \"d\")\n",
    "class_rep = classification_report(y_test, PredicGradB)\n",
    "gradB_score = accuracy_score(y_test, PredicGradB)\n",
    "print(class_rep)\n",
    "print(\"Accuracy: \", gradB_score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ada Boost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "adaB = AdaBoostClassifier(dTree,random_state=42)\n",
    "adaB.fit(X_train_transformed,y_train)\n",
    "\n",
    "#make predictions\n",
    "PredicAdaB = adaB.predict(X_test_transformed)\n",
    "\n",
    "#evaluate predictions\n",
    "confmat = confusion_matrix(y_test, PredicAdaB)\n",
    "sns.heatmap(confmat, annot = True, fmt = \"d\")\n",
    "class_rep = classification_report(y_test, PredicAdaB)\n",
    "adaB_score = accuracy_score(y_test, PredicAdaB)\n",
    "print(class_rep)\n",
    "print(\"Accuracy: \", adaB_score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### XG boost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#fit the model\n",
    "xgB = XGBClassifier(random_state=42,n_jobs=-1)\n",
    "xgB.fit(X_train_transformed,y_train)\n",
    "\n",
    "#make predictions\n",
    "PredicXgb = xgB.predict(X_test_transformed)\n",
    "\n",
    "#evaluate predictions\n",
    "confmat = confusion_matrix(y_test, PredicXgb)\n",
    "sns.heatmap(confmat, annot = True, fmt = \"d\")\n",
    "class_rep = classification_report(y_test, PredicXgb)\n",
    "xgB_score = accuracy_score(y_test, PredicXgb)\n",
    "print(class_rep)\n",
    "print(\"Accuracy: \", xgB_score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bagging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#fit the model\n",
    "bagN = BaggingClassifier(Knn)\n",
    "bagN.fit(X_train_transformed,y_train)\n",
    "\n",
    "#make predictions\n",
    "PredicBagN = bagN.predict(X_test_transformed)\n",
    "\n",
    "#evaluate predictions\n",
    "confmat = confusion_matrix(y_test, PredicBagN)\n",
    "sns.heatmap(confmat, annot = True, fmt = \"d\")\n",
    "class_rep = classification_report(y_test, PredicBagN)\n",
    "bagN_score = accuracy_score(y_test, PredicBagN)\n",
    "print(class_rep)\n",
    "print(\"Accuracy: \", bagN_score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Stacking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#fit the model\n",
    "estimators=[\n",
    "    ('Logistic Regression',logR_grid_Search),\n",
    "    ('Random Forest',RFor_grid_Search),\n",
    "    ('GRadient Boosting',gradB_grid_Search)]\n",
    "Stk = StackingClassifier(estimators = estimators,final_estimator= xgB_grid_Search)\n",
    "Stk.fit(X_train_transformed,Y_train)\n",
    "\n",
    "#make predictions\n",
    "PredicStk = Stk.predict(X_test_transformed)\n",
    "#evaluate predictions\n",
    "confmat = confusion_matrix(Y_test, PredicStk)\n",
    "sns.heatmap(confmat, annot = True, fmt = \"d\")\n",
    "class_rep = classification_report(Y_test, PredicStk)\n",
    "Stk_score = accuracy_score(Y_test, PredicStk)\n",
    "print(class_rep1)\n",
    "print(\"Accuracy: \", Stk_score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Scores = pd.DataFrame({\n",
    "    'Model':['KNeighborsClassifier','LogisticRegressionClassifier','DecisionTreeClassifier','RandomForestClassifier','GradientBoostClassifier','AdaBoostClassifier','XGBoostClassifier','BaggingClassifier','StackingClassifier'],\n",
    "    'Accuracy':[Knn_score,logR_score,dTree_score,RFor_score,gradB_score,adaB_score,xgB_score,bagN_score,Stk_score]})\n",
    "Scores"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Conclusion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Which is the best classifier?**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 315,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The best Classifier is Stacking with a Accuracy of  0.64736\n"
     ]
    }
   ],
   "source": [
    "print(\"The best Classifier is Stacking with a Accuracy of \",Scores['Accuracy'].max())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Is it really the best classifier?**\n",
    "\n",
    "I think XgBoost is better than Stacking, Accuracy wise Stacking is better but there is only a diffrence of 0.00528 but stacking ran 6 times as long as Xg Boost."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
